{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter pack\n",
    "\n",
    "This notebook shows:\n",
    "\n",
    "- how to load samples from PASTIS using the dataloaders provided in the repository.\n",
    "- how to visualize the images\n",
    "- compute the challenge metric\n",
    "- make a random submission\n",
    "- explain how your submissions will be processed automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill these file paths with the locations on your machine.\n",
    "# PATH_TO_CODE = \"/Users/louis.stefanuto.c/Documents/pastis-benchmark-mines2024/baseline/\"\n",
    "PATH_TO_DATA = (\n",
    "    \"/Users/louis.stefanuto.c/Documents/pastis-benchmark-mines2024/DATA-mini/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data folder should have this hierarchy:\n",
    "\n",
    "```\n",
    ".\n",
    "â”œâ”€â”€ TRAIN/\n",
    "â”‚   â”œâ”€â”€ DATA_S2/\n",
    "â”‚   â”‚   â”œâ”€â”€ S2_10000.npy\n",
    "â”‚   â”‚   â”œâ”€â”€ S2_10001.npy\n",
    "â”‚   â”‚   â”œâ”€â”€ S2_10002.npy\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â”œâ”€â”€ ANNOTATIONS/\n",
    "â”‚   â”‚   â”œâ”€â”€ TARGET_10000.npy\n",
    "â”‚   â”‚   â”œâ”€â”€ TARGET_10001.npy\n",
    "â”‚   â”‚   â”œâ”€â”€ TARGET_10002.npy\n",
    "â”‚   â”‚   â””â”€â”€ ...\n",
    "â”‚   â””â”€â”€ metadata.json\n",
    "â””â”€â”€ TEST/\n",
    "    â”œâ”€â”€ DATA_S2\n",
    "    â”‚   â””â”€â”€ ...\n",
    "    â””â”€â”€ metadata.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoJson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geojson file contains all the metadata about the patch sequences (id, dates of the sentinel 2 images, geometry of the parcels ...)\n",
    "\n",
    "- ID: unique id of the patch\n",
    "- N_Parcel: nb of parcels in the patch\n",
    "- Parcel_Cover: % of the patch covered by land\n",
    "- region: the patches are sampled from various regions, we added this information if you want to apply region-based normalization/transformations ...\n",
    "- dates-S2: dates of the images in the sequence for this patch\n",
    "- geometry: multipolygon shape telling where the parcels are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "\n",
    "METADATA = Path(PATH_TO_DATA) / \"metadata.geojson\"\n",
    "\n",
    "mtd = gpd.read_file(METADATA)\n",
    "mtd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel images - Loading and viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline.dataset import BaselineDataset\n",
    "from baseline.collate import pad_collate\n",
    "\n",
    "# Set seeds for PyTorch and numpy\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "dt = BaselineDataset(Path(PATH_TO_DATA))\n",
    "\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    dt, batch_size=32, collate_fn=pad_collate, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's query a batch from the dataloader:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dl.__iter__().__next__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch is made of:\n",
    "\n",
    "- an **image tensor** of shape $(B, T, C, H, W)$, where:\n",
    "  - $B$ is the batch size\n",
    "  - $T$ is the temporal length of the image time series\n",
    "  - $(C, H, W)$ is the dimension of the patches, channel first\n",
    "- a **label tensor** of shape $(B, H, W)$, the semantic segmentation ground truth mask (with values in $[0, 19]$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[\"S2\"].shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have a batch of sequences and their corresponding mask labels. First let's have a look at a single sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline.viz import plot_sequence_grid\n",
    "\n",
    "IDX_IMG = 1  # Choose your sequence in [0, BATCH_SIZE-1]\n",
    "\n",
    "plot_sequence_grid(x, bid=IDX_IMG, N=15, M=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a single image from this sequence (left) and its corresponding mask (right). The mask is your target, what you have to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline.viz import plot_s2_and_labels\n",
    "\n",
    "plot_s2_and_labels(x, y, bid=IDX_IMG, t_show=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "The challenge metric is the mean Intersection over Union.\n",
    "\n",
    "- For each class, compute the binary IoU\n",
    "- Average the IoUs (`average=\"macro\"`)\n",
    "\n",
    "We use the sklearn `jaccard_score` function for all the evaluation tasks (see later).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "NUM_CLASSES = 20\n",
    "BATCH_SHAPE = y.shape  # (C, H, W)\n",
    "\n",
    "np.random.seed(1234)  # for replicable results\n",
    "\n",
    "# Create a random prediction matrix\n",
    "preds = np.random.randint(low=0, high=NUM_CLASSES, size=BATCH_SHAPE)\n",
    "\n",
    "# Compare it to the ground truth\n",
    "miou = jaccard_score(y.flatten(), preds.flatten(), average=\"macro\")\n",
    "print(\"miou:\", miou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "This section shows you how to submit predictions on Kaggle.\n",
    "\n",
    "Your submission must be in the CSV format. It should have two columns:\n",
    "\n",
    "- **ID**: the ID of the image\n",
    "- **MASKS**: contains the 1D-flattened string conversion of the 2D segmentation masks\n",
    "\n",
    "To generate the `MASKS` column, we provide you a `masks_to_str` function. We also provide the decoding script so you have a plain understanding of how we will process your submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline.submission_tools import decode_masks, masks_to_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate a random submission (and solution)\n",
    "\n",
    "> Note: 474 is the size of the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "np.random.seed(1234)\n",
    "\n",
    "X = np.random.randint(0, NUM_CLASSES, size=(474, 128, 128), dtype=np.uint8)\n",
    "masks = masks_to_str(X)\n",
    "print(X.shape)\n",
    "\n",
    "submission = pd.DataFrame.from_dict({\"ID\": range(len(X)), \"MASKS\": masks})\n",
    "submission[\"ID\"] = submission[\"ID\"] + 20000\n",
    "\n",
    "# Note that the index=False argument is important.\n",
    "submission.to_csv(\"submission_random.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that the test set is splitted into two subsets: a public set (50%) and a private set (50%).\n",
    "\n",
    "During the competition, your scores will be computed **only on the public score**.\n",
    "\n",
    "At the end of the competition, your scores will be updated to take with your score on the private set into account. The goal is to avoid indirect overfitting on the test set via repeated submissions. This will also add some suspense at the end of the challenge ðŸ˜‡.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation pipeline\n",
    "\n",
    "(Useless for predictions but may be useful if you have issues when submitting)\n",
    "\n",
    "Here is a short review of how our automated pipeline evaluates your predictions against the test ground truths:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"submission_random.csv\")\n",
    "\n",
    "# Verify the shape of the restored array\n",
    "X_restored = decode_masks(df[\"MASKS\"].to_list())\n",
    "print(X_restored.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the restored submission batch is the same as the one you submitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction test - Should be True\n",
    "(X == X_restored).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the mIOU between the original prediction batch tensor and its restored version.\n",
    "\n",
    "If everything went well, the cell should return `1.0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miou = jaccard_score(X.flatten(), X_restored.flatten(), average=\"macro\")\n",
    "print(\"miou:\", miou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here is the evaluation pipeline in Kaggle. It incorporates all the aforementioned elements. Note that Kaggle opens your CSV with Pandas before the `score` function. It expects the `ID` column to be the first one of your CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Enter any documentation that only people updating the metric should read here.\n",
    "\n",
    "All columns of the solution and submission dataframes are passed to your metric, except for the Usage column.\n",
    "\n",
    "Your metric must satisfy the following constraints:\n",
    "- You must have a function named score. Kaggle's evaluation system will call that function.\n",
    "- You can add your own arguments to score, but you cannot change the first three (solution, submission, and row_id_column_name).\n",
    "- All arguments for score must have type annotations.\n",
    "- score must return a single, finite, non-null float.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    # If you want an error message to be shown to participants, you must raise the error as a ParticipantVisibleError\n",
    "    # All other errors will only be shown to the competition host. This helps prevent unintentional leakage of solution data.\n",
    "    pass\n",
    "\n",
    "\n",
    "def decode_masks(\n",
    "    masks: list[str],\n",
    "    target_shape: tuple[int, int] = (128, 128),\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert each string in masks back to a 1D list of integers.\n",
    "\n",
    "    Args:\n",
    "        masks (list[str]): list of stringified masks\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: reconstructed batch of masks\n",
    "    \"\"\"\n",
    "    return np.array(\n",
    "        [\n",
    "            np.fromstring(mask, sep=\" \", dtype=np.uint8).reshape(target_shape)\n",
    "            for mask in masks\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def score(\n",
    "    solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Scoring function. Takes the solution and submission and returns the mIOU.\n",
    "    \"\"\"\n",
    "    # Check submission files\n",
    "    COL_MASK = \"MASKS\"\n",
    "    expected_columns = [\"ID\", COL_MASK]\n",
    "    for col in expected_columns:\n",
    "        if col not in submission.columns:\n",
    "            raise ParticipantVisibleError(\n",
    "                f\"Required column: {col} not found in the submission dataframe. Check your column names.\"\n",
    "            )\n",
    "\n",
    "    if not pandas.api.types.is_string_dtype(submission[COL_MASK]):\n",
    "        raise ParticipantVisibleError(\n",
    "            f\"Submission column {col} must be an object (str) column.\"\n",
    "        )\n",
    "\n",
    "    # Parse and decode the masks into tensors\n",
    "    masks_submission = decode_masks(submission[COL_MASK].to_list())\n",
    "    masks_solution = decode_masks(solution[COL_MASK].to_list())\n",
    "\n",
    "    if not masks_submission.shape == masks_solution.shape:\n",
    "        raise ParticipantVisibleError(\n",
    "            f\"Submission should be of shape {masks_solution.shape} after decoding. Got submission.shape: {masks_submission.shape}.\"\n",
    "        )\n",
    "\n",
    "    return jaccard_score(\n",
    "        y_true=masks_solution.flatten(),\n",
    "        y_pred=masks_submission.flatten(),\n",
    "        average=\"macro\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline-ThK6kykJ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
